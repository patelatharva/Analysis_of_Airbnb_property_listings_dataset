{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-optimize in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (0.5.2)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from scikit-optimize) (0.20.3)\n",
      "Requirement already satisfied: numpy in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from scikit-optimize) (1.16.2)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from scikit-optimize) (1.2.1)\n",
      "Requirement already satisfied: hyperopt in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (0.1.2)\n",
      "Requirement already satisfied: scipy in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from hyperopt) (1.2.1)\n",
      "Requirement already satisfied: networkx in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from hyperopt) (2.2)\n",
      "Requirement already satisfied: future in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from hyperopt) (0.17.1)\n",
      "Requirement already satisfied: pymongo in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from hyperopt) (3.9.0)\n",
      "Requirement already satisfied: six in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from hyperopt) (1.12.0)\n",
      "Requirement already satisfied: numpy in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from hyperopt) (1.16.2)\n",
      "Requirement already satisfied: tqdm in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from hyperopt) (4.31.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from networkx->hyperopt) (4.4.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import seaborn as sns\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "import math\n",
    "from sklearn.base import clone\n",
    "!pip install scikit-optimize\n",
    "from skopt import gp_minimize\n",
    "!pip install hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt import space_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calendar_dfs = []\n",
    "# for file_name in glob.glob('./data/amsterdam/calendar*.gz'):\n",
    "#     calendar_dfs.append(pd.read_csv(file_name, compression='gzip'))\n",
    "# calendar = pd.concat(calendar_dfs, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_dfs = []\n",
    "# for file_name in glob.glob('./data/amsterdam/reviews*.gz'):\n",
    "#     reviews_dfs.append(pd.read_csv(file_name, compression='gzip'))\n",
    "# reviews = pd.concat(reviews_dfs, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listings_dfs = []\n",
    "# for file_name in glob.glob('./data/amsterdam/listings*.gz'):\n",
    "#     listings_dfs.append(pd.read_csv(file_name, compression='gzip', dtype=\"str\"))\n",
    "# listings = pd.concat(listings_dfs, sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar = pd.read_csv(\"./data/boston/calendar.csv\")\n",
    "reviews = pd.read_csv(\"./data/boston/reviews.csv\")\n",
    "listings = pd.read_csv(\"./data/boston/listings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming 'price' from string to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    250.0\n",
       "1     65.0\n",
       "2     65.0\n",
       "3     75.0\n",
       "4     79.0\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Converts price in the string format like \"$1,125.00\" into numeric value 1125.00\n",
    "    INPUT:\n",
    "    - string price in string format\n",
    "    OUTPUT:\n",
    "    - float value corresponding to the price or None if the input is not parseable to float\n",
    "\"\"\"\n",
    "def str_to_num (string):\n",
    "    if string is not None:\n",
    "        if type(string) is str and string.startswith('$'):\n",
    "            return float(string.replace('$', '').replace(',', ''))\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "listings_cleaned = pd.concat([listings.drop('price', axis=1), listings[\"price\"].apply(str_to_num)], axis=1)\n",
    "listings_cleaned['price'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   NaN\n",
       "1   NaN\n",
       "2   NaN\n",
       "3   NaN\n",
       "4   NaN\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar_cleaned = pd.concat([calendar.drop('price', axis=1), calendar[\"price\"].apply(str_to_num)], axis=1)\n",
    "calendar_cleaned['price'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting 'avilable' field from string to binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "Name: available, dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar_cleaned['available'] = calendar_cleaned['available'] == 't'\n",
    "calendar_cleaned['available'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting 'date' from string to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_cleaned[\"date\"] = pd.to_datetime(calendar_cleaned[\"date\"], format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting location field from numeric to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_cleaned[\"location_categorical\"] = listings_cleaned.apply(lambda row: str((format(row.latitude, '.2f'), format(row.longitude, '.2f'))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ('42.28', '-71.13')\n",
       "1    ('42.29', '-71.13')\n",
       "2    ('42.29', '-71.14')\n",
       "3    ('42.28', '-71.12')\n",
       "4    ('42.28', '-71.14')\n",
       "Name: location_categorical, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_cleaned.location_categorical.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting 'amenities' field containing list into separate categorical columns for each amenity in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TV',\n",
       " 'Wireless Internet',\n",
       " 'Kitchen',\n",
       " 'Free Parking on Premises',\n",
       " 'Pets live on this property',\n",
       " 'Dog(s)',\n",
       " 'Heating',\n",
       " 'Family/Kid Friendly',\n",
       " 'Washer',\n",
       " 'Dryer',\n",
       " 'Smoke Detector',\n",
       " 'Fire Extinguisher',\n",
       " 'Essentials',\n",
       " 'Shampoo',\n",
       " 'Laptop Friendly Workspace']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda amenity : amenity.replace(\"\\\"\",\"\").replace(\"{\",\"\").replace(\"}\", \"\"), listings_cleaned.amenities.iloc[0].split(\",\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Separates the string value of `amenities` attribute in the row, into a list of individual amenities.\n",
    "    \n",
    "    INPUT:\n",
    "    - row : from dataset having amenities attribute\n",
    "    OUTPUT:    \n",
    "    - list of amenities derived from the value of `amenities` attribute in row\n",
    "\"\"\"\n",
    "def separate_amenities(row):\n",
    "    amenities = row.amenities\n",
    "    list_to_return = []\n",
    "    if (amenities is not None and type(amenities) == str):            \n",
    "        list_to_return = list(map(lambda amenity : amenity.replace(\"\\\"\",\"\").replace(\"{\",\"\").replace(\"}\", \"\"), amenities.split(\",\")))\n",
    "    if '' in list_to_return:\n",
    "        list_to_return.remove('')\n",
    "    return list_to_return\n",
    "listings_cleaned[\"amenities_list\"] = listings_cleaned.apply(separate_amenities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TV', 'Wireless Internet', 'Kitchen', 'Free Parking on Premises',\n",
       "       'Pets live on this property', 'Dog(s)', 'Heating',\n",
       "       'Family/Kid Friendly', 'Washer', 'Dryer', 'Smoke Detector',\n",
       "       'Fire Extinguisher', 'Essentials', 'Shampoo',\n",
       "       'Laptop Friendly Workspace', 'Internet', 'Air Conditioning',\n",
       "       'Pets Allowed', 'Carbon Monoxide Detector', 'Lock on Bedroom Door',\n",
       "       'Hangers', 'Hair Dryer', 'Iron', 'Cable TV', 'First Aid Kit',\n",
       "       'Safety Card', 'translation missing: en.hosting_amenity_49',\n",
       "       'translation missing: en.hosting_amenity_50', 'Gym', 'Breakfast',\n",
       "       'Indoor Fireplace', 'Cat(s)', '24-Hour Check-in', 'Hot Tub',\n",
       "       'Buzzer/Wireless Intercom', 'Other pet(s)', 'Washer / Dryer',\n",
       "       'Smoking Allowed', 'Suitable for Events', 'Wheelchair Accessible',\n",
       "       'Elevator in Building', 'Pool', 'Doorman',\n",
       "       'Paid Parking Off Premises', 'Free Parking on Street'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_amenities = listings_cleaned['amenities_list'].apply(pd.Series).stack().unique()\n",
    "possible_amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Assigns new boolean attribute to the row based on the presence of that amenity in the list.\n",
    "    Returns updated row with additional attributes corresponding to the amenities added to it.\n",
    "    \n",
    "    INPUT:\n",
    "    - row containing attributes related to the property, including `amenities_list`\n",
    "    OUTPUT:\n",
    "    - row containing newly added boolean attributes indicating the presence of each possible type of amenity in the property\n",
    "\"\"\"\n",
    "def add_amenities_columns (row):\n",
    "    amenities = set(row.amenities_list)\n",
    "    for possible_amenity in possible_amenities:\n",
    "        row[\"amenity_\" + possible_amenity] = possible_amenity in amenities\n",
    "    return row\n",
    "\n",
    "listings_cleaned = listings_cleaned.apply(add_amenities_columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the activation date for each property listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>date</th>\n",
       "      <th>available</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3353</td>\n",
       "      <td>2017-09-05</td>\n",
       "      <td>True</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3353</td>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3353</td>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>True</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3353</td>\n",
       "      <td>2016-10-12</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5506</td>\n",
       "      <td>2017-09-05</td>\n",
       "      <td>True</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5506</td>\n",
       "      <td>2016-10-10</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5506</td>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>True</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5506</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5506</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>True</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5506</td>\n",
       "      <td>2016-09-25</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5506</td>\n",
       "      <td>2016-09-22</td>\n",
       "      <td>True</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5506</td>\n",
       "      <td>2016-09-21</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5506</td>\n",
       "      <td>2016-09-19</td>\n",
       "      <td>True</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5506</td>\n",
       "      <td>2016-09-18</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5506</td>\n",
       "      <td>2016-09-15</td>\n",
       "      <td>True</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5506</td>\n",
       "      <td>2016-09-12</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5506</td>\n",
       "      <td>2016-09-08</td>\n",
       "      <td>True</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6695</td>\n",
       "      <td>2017-09-05</td>\n",
       "      <td>True</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6695</td>\n",
       "      <td>2016-10-24</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6695</td>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>True</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    listing_id       date  available  price\n",
       "0         3353 2017-09-05       True   36.0\n",
       "1         3353 2016-12-30      False    NaN\n",
       "2         3353 2017-08-18       True   36.0\n",
       "3         3353 2016-10-12      False    NaN\n",
       "4         5506 2017-09-05       True  145.0\n",
       "5         5506 2016-10-10      False    NaN\n",
       "6         5506 2016-10-03       True  145.0\n",
       "7         5506 2016-09-30      False    NaN\n",
       "8         5506 2016-09-28       True  145.0\n",
       "9         5506 2016-09-25      False    NaN\n",
       "10        5506 2016-09-22       True  145.0\n",
       "11        5506 2016-09-21      False    NaN\n",
       "12        5506 2016-09-19       True  145.0\n",
       "13        5506 2016-09-18      False    NaN\n",
       "14        5506 2016-09-15       True  145.0\n",
       "15        5506 2016-09-12      False    NaN\n",
       "16        5506 2016-09-08       True  145.0\n",
       "17        6695 2017-09-05       True  195.0\n",
       "18        6695 2016-10-24      False    NaN\n",
       "19        6695 2016-10-19       True  195.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = calendar_cleaned\n",
    "df = df.groupby('listing_id', group_keys=False)\\\n",
    "    .apply(lambda x: x[x.available.ne(x.available.shift())])\\\n",
    "    .reset_index(drop=True)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_activation_dates = df[df.available == True].groupby(\"listing_id\")[[\"listing_id\",\"date\"]].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listing_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>530983</th>\n",
       "      <td>530983</td>\n",
       "      <td>2016-09-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815639</th>\n",
       "      <td>815639</td>\n",
       "      <td>2016-09-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12726343</th>\n",
       "      <td>12726343</td>\n",
       "      <td>2016-09-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2776391</th>\n",
       "      <td>2776391</td>\n",
       "      <td>2016-09-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10524612</th>\n",
       "      <td>10524612</td>\n",
       "      <td>2016-09-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            listing_id       date\n",
       "listing_id                       \n",
       "530983          530983 2016-09-06\n",
       "815639          815639 2016-09-06\n",
       "12726343      12726343 2016-09-06\n",
       "2776391        2776391 2016-09-06\n",
       "10524612      10524612 2016-09-06"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listing_activation_dates.sort_values(by=[\"date\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only retaining entries in calendar for each property after its activation date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_by_listing_groups = calendar_cleaned.groupby([\"listing_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>date</th>\n",
       "      <th>available</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12147973</td>\n",
       "      <td>2017-09-05</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12147973</td>\n",
       "      <td>2017-09-04</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12147973</td>\n",
       "      <td>2017-09-03</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12147973</td>\n",
       "      <td>2017-09-02</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12147973</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>3075044</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>True</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>3075044</td>\n",
       "      <td>2017-08-21</td>\n",
       "      <td>True</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>3075044</td>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>True</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>3075044</td>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>True</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>3075044</td>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>True</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>6976</td>\n",
       "      <td>2017-05-12</td>\n",
       "      <td>True</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>6976</td>\n",
       "      <td>2017-05-11</td>\n",
       "      <td>True</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>6976</td>\n",
       "      <td>2017-05-10</td>\n",
       "      <td>True</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>6976</td>\n",
       "      <td>2017-05-09</td>\n",
       "      <td>True</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>6976</td>\n",
       "      <td>2017-05-08</td>\n",
       "      <td>True</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>1436513</td>\n",
       "      <td>2017-05-10</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>1436513</td>\n",
       "      <td>2017-05-09</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>1436513</td>\n",
       "      <td>2017-05-08</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>1436513</td>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>True</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>1436513</td>\n",
       "      <td>2017-05-06</td>\n",
       "      <td>True</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>7651065</td>\n",
       "      <td>2017-06-21</td>\n",
       "      <td>True</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>7651065</td>\n",
       "      <td>2017-06-20</td>\n",
       "      <td>True</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>7651065</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>True</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>7651065</td>\n",
       "      <td>2017-06-18</td>\n",
       "      <td>True</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>7651065</td>\n",
       "      <td>2017-06-17</td>\n",
       "      <td>True</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>12386020</td>\n",
       "      <td>2017-04-25</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>12386020</td>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>12386020</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>12386020</td>\n",
       "      <td>2017-04-22</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>12386020</td>\n",
       "      <td>2017-04-21</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306700</th>\n",
       "      <td>14852179</td>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306701</th>\n",
       "      <td>14852179</td>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306702</th>\n",
       "      <td>14852179</td>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306703</th>\n",
       "      <td>14852179</td>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306704</th>\n",
       "      <td>14852179</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307065</th>\n",
       "      <td>8373729</td>\n",
       "      <td>2017-05-18</td>\n",
       "      <td>True</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307066</th>\n",
       "      <td>8373729</td>\n",
       "      <td>2017-05-17</td>\n",
       "      <td>True</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307067</th>\n",
       "      <td>8373729</td>\n",
       "      <td>2017-05-16</td>\n",
       "      <td>True</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307068</th>\n",
       "      <td>8373729</td>\n",
       "      <td>2017-05-15</td>\n",
       "      <td>True</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307069</th>\n",
       "      <td>8373729</td>\n",
       "      <td>2017-05-14</td>\n",
       "      <td>True</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307430</th>\n",
       "      <td>14844274</td>\n",
       "      <td>2017-06-22</td>\n",
       "      <td>True</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307431</th>\n",
       "      <td>14844274</td>\n",
       "      <td>2017-06-21</td>\n",
       "      <td>True</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307432</th>\n",
       "      <td>14844274</td>\n",
       "      <td>2017-06-20</td>\n",
       "      <td>True</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307433</th>\n",
       "      <td>14844274</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>True</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307434</th>\n",
       "      <td>14844274</td>\n",
       "      <td>2017-06-18</td>\n",
       "      <td>True</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307795</th>\n",
       "      <td>14585486</td>\n",
       "      <td>2017-09-05</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307796</th>\n",
       "      <td>14585486</td>\n",
       "      <td>2017-09-04</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307797</th>\n",
       "      <td>14585486</td>\n",
       "      <td>2017-09-03</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307798</th>\n",
       "      <td>14585486</td>\n",
       "      <td>2017-09-02</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307799</th>\n",
       "      <td>14585486</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308160</th>\n",
       "      <td>14603878</td>\n",
       "      <td>2017-09-05</td>\n",
       "      <td>True</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308161</th>\n",
       "      <td>14603878</td>\n",
       "      <td>2017-09-04</td>\n",
       "      <td>True</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308162</th>\n",
       "      <td>14603878</td>\n",
       "      <td>2017-09-03</td>\n",
       "      <td>True</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308163</th>\n",
       "      <td>14603878</td>\n",
       "      <td>2017-09-02</td>\n",
       "      <td>True</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308164</th>\n",
       "      <td>14603878</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>True</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308525</th>\n",
       "      <td>14504422</td>\n",
       "      <td>2017-06-21</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308526</th>\n",
       "      <td>14504422</td>\n",
       "      <td>2017-06-20</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308527</th>\n",
       "      <td>14504422</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308528</th>\n",
       "      <td>14504422</td>\n",
       "      <td>2017-06-18</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308529</th>\n",
       "      <td>14504422</td>\n",
       "      <td>2017-06-17</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17925 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         listing_id       date  available  price\n",
       "0          12147973 2017-09-05      False    NaN\n",
       "1          12147973 2017-09-04      False    NaN\n",
       "2          12147973 2017-09-03      False    NaN\n",
       "3          12147973 2017-09-02      False    NaN\n",
       "4          12147973 2017-09-01      False    NaN\n",
       "365         3075044 2017-08-22       True   65.0\n",
       "366         3075044 2017-08-21       True   65.0\n",
       "367         3075044 2017-08-20       True   65.0\n",
       "368         3075044 2017-08-19       True   75.0\n",
       "369         3075044 2017-08-18       True   75.0\n",
       "730            6976 2017-05-12       True   65.0\n",
       "731            6976 2017-05-11       True   65.0\n",
       "732            6976 2017-05-10       True   65.0\n",
       "733            6976 2017-05-09       True   65.0\n",
       "734            6976 2017-05-08       True   65.0\n",
       "1095        1436513 2017-05-10      False    NaN\n",
       "1096        1436513 2017-05-09      False    NaN\n",
       "1097        1436513 2017-05-08      False    NaN\n",
       "1098        1436513 2017-05-07       True   75.0\n",
       "1099        1436513 2017-05-06       True   75.0\n",
       "1460        7651065 2017-06-21       True   79.0\n",
       "1461        7651065 2017-06-20       True   79.0\n",
       "1462        7651065 2017-06-19       True   79.0\n",
       "1463        7651065 2017-06-18       True   79.0\n",
       "1464        7651065 2017-06-17       True   79.0\n",
       "1825       12386020 2017-04-25      False    NaN\n",
       "1826       12386020 2017-04-24      False    NaN\n",
       "1827       12386020 2017-04-23      False    NaN\n",
       "1828       12386020 2017-04-22      False    NaN\n",
       "1829       12386020 2017-04-21      False    NaN\n",
       "...             ...        ...        ...    ...\n",
       "1306700    14852179 2017-08-20      False    NaN\n",
       "1306701    14852179 2017-08-19      False    NaN\n",
       "1306702    14852179 2017-08-18      False    NaN\n",
       "1306703    14852179 2017-08-17      False    NaN\n",
       "1306704    14852179 2017-08-16      False    NaN\n",
       "1307065     8373729 2017-05-18       True   69.0\n",
       "1307066     8373729 2017-05-17       True   69.0\n",
       "1307067     8373729 2017-05-16       True   69.0\n",
       "1307068     8373729 2017-05-15       True   69.0\n",
       "1307069     8373729 2017-05-14       True   69.0\n",
       "1307430    14844274 2017-06-22       True  150.0\n",
       "1307431    14844274 2017-06-21       True  150.0\n",
       "1307432    14844274 2017-06-20       True  150.0\n",
       "1307433    14844274 2017-06-19       True  150.0\n",
       "1307434    14844274 2017-06-18       True  150.0\n",
       "1307795    14585486 2017-09-05      False    NaN\n",
       "1307796    14585486 2017-09-04      False    NaN\n",
       "1307797    14585486 2017-09-03      False    NaN\n",
       "1307798    14585486 2017-09-02      False    NaN\n",
       "1307799    14585486 2017-09-01      False    NaN\n",
       "1308160    14603878 2017-09-05       True   59.0\n",
       "1308161    14603878 2017-09-04       True   59.0\n",
       "1308162    14603878 2017-09-03       True   59.0\n",
       "1308163    14603878 2017-09-02       True   59.0\n",
       "1308164    14603878 2017-09-01       True   59.0\n",
       "1308525    14504422 2017-06-21      False    NaN\n",
       "1308526    14504422 2017-06-20      False    NaN\n",
       "1308527    14504422 2017-06-19      False    NaN\n",
       "1308528    14504422 2017-06-18      False    NaN\n",
       "1308529    14504422 2017-06-17      False    NaN\n",
       "\n",
       "[17925 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_by_listing_groups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_entries_after_activation_date(g):\n",
    "\n",
    "    listing_id = g.name\n",
    "    activation_date_df = listing_activation_dates.query(\"listing_id == @listing_id\")[\"date\"]\n",
    "    if activation_date_df.shape[0] > 0:        \n",
    "        activation_date = activation_date_df.iloc[0]\n",
    "#         print(\"activatation_date: \" + str(activation_date))\n",
    "#         print(g[\"date\"].dtype)\n",
    "#         print(type(activation_date))\n",
    "        return g[g[\"date\"] <= activation_date]\n",
    "    \n",
    "    \n",
    "cal_after_activation_dates =cal_by_listing_groups.apply(select_entries_after_activation_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select and add necessary variables to be used for predicting occupancy of property at given time of the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vars_from_listings = [\"neighbourhood_cleansed\", \n",
    "#                 \"neighbourhood_group_cleansed\",\n",
    "                \"city\",\n",
    "                \"state\",\n",
    "                \"zipcode\",\n",
    "                \"market\",\n",
    "                \"location_categorical\",\n",
    "                \"property_type\",\n",
    "                \"room_type\",\n",
    "                \"accommodates\",\n",
    "                \"bathrooms\",\n",
    "                \"bedrooms\",\n",
    "                \"beds\",\n",
    "                \"bed_type\",\n",
    "                \"square_feet\",\n",
    "                \"guests_included\",\n",
    "                \"minimum_nights\",\n",
    "                \"maximum_nights\",\n",
    "                \"review_scores_rating\",\n",
    "                \"review_scores_accuracy\",\n",
    "                  \"review_scores_cleanliness\",\n",
    "                  \"review_scores_checkin\",\n",
    "                  \"review_scores_communication\",\n",
    "                  \"review_scores_location\",\n",
    "                  \"review_scores_value\",\n",
    "#                   \"jurisdiction_names\",\n",
    "                  \"cancellation_policy\",\n",
    "#                   \"reviews_per_month\",\n",
    "                  \"number_of_reviews\"\n",
    "       ]\n",
    "amenity_variables = list(map(lambda amenity : \"amenity_\" + amenity, possible_amenities))\n",
    "input_vars_from_listings.extend(amenity_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_cleaned[\"month\"] = calendar_cleaned['date'].dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_cleaned[\"day_of_week\"] = calendar_cleaned['date'].dt.weekday_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_cleaned[\"week_of_month\"] = np.ceil(calendar_cleaned['date'].dt.day/7).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 4, 3, 2])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar_cleaned[\"week_of_month\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(listings_cleaned, calendar_cleaned, left_on=\"id\", right_on=\"listing_id\", how=\"inner\", suffixes=(\"_listings\", \"_calendar\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = df.groupby([\"listing_id\"]).apply(lambda x: x.sort_values(by=[\"date\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.loc[:, \"price_calendar\"] = g[\"price_calendar\"].fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = g.drop(columns=[\"listing_id\"]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vars_from_calendar = [\"month\", \"day_of_week\", \"week_of_month\", \"price_calendar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_input_vars = input_vars_from_listings + input_vars_from_calendar;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"available\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[all_input_vars + [\"listing_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"available\"] + [\"listing_id\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing values in numeric columns with mean of the corresponding column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = X.select_dtypes(exclude=['object']).copy().columns\n",
    "def fill_mean (col):\n",
    "    return col.fillna(col.mean())\n",
    "X.loc[X.index, num_vars] = X[num_vars].apply(fill_mean, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert categorical variables into numeric variables with separate column for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = X.select_dtypes(include=['object']).copy().columns\n",
    "for var in  cat_vars:\n",
    "    # for each cat add dummy var, drop original column\n",
    "    X = pd.concat([X.drop(var, axis=1), pd.get_dummies(X[var], prefix=var, prefix_sep='_', drop_first=False, dummy_na=True)], axis=1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into training and test sets while making sure that no property listing is common between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_listing_ids = X[\"listing_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "listing_ids_train = np.random.choice(np.array(unique_listing_ids), size= int(0.70 * len(unique_listing_ids)), replace=False)\n",
    "listing_ids_test = [l for l in unique_listing_ids if l not in listing_ids_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.query(\"listing_id in @listing_ids_train\")\n",
    "y_train = y.query(\"listing_id in @listing_ids_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.index == y_train.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using here only a smaller sample of training data to choose hyper parameters using cross validation technique to complete the experiments in timely manner. However, in real world scenario with availability of time, higher computational resources and memory, entire training dataset should be used for choosing optimal hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample = X_train.sample(10000)\n",
    "y_train_sample = y.loc[X_train_sample.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X.query(\"listing_id in @listing_ids_test\").drop(columns=[\"listing_id\"])\n",
    "y_test = y.query(\"listing_id in @listing_ids_test\").drop(columns=[\"listing_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(\"X_test.csv\", index=False)\n",
    "y_test.to_csv(\"y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.510366\n",
       "True     0.489634\n",
       "Name: available, dtype: float64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[\"available\"].value_counts()/y_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the ratio of samples classified for output True and False, the data looks to be balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing cross validation splits to into training and test sets while making sure that no property listing is common between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGridSearchCV(object):\n",
    "    \n",
    "    def __init__(self, estimator, param_grid, cv=3):\n",
    "        self.estimator = estimator\n",
    "        self.param_grid = param_grid\n",
    "        self.best_score = -math.inf\n",
    "        self.best_estimator = None\n",
    "        self.best_estimator_scores_mean = -math.inf\n",
    "        self.best_estimator_scores_stdev = -math.inf\n",
    "        self.best_params= None\n",
    "        self.cv = cv       \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        for param_point in self.get_param_grid_points():\n",
    "            def splits(array, k):\n",
    "                splits = []\n",
    "                \n",
    "                for i in range(k):\n",
    "                    split_length = math.ceil(len(array)/k)\n",
    "                    split = []\n",
    "                    for j in range(i * split_length, (i+1) * split_length):\n",
    "                        if j < len(array):\n",
    "                            split.append(array[j])\n",
    "                        \n",
    "                    splits.append(split)\n",
    "                cvs = []\n",
    "                for i, split in enumerate(splits):\n",
    "                    train = []\n",
    "                    for j, other_split in enumerate(splits):\n",
    "                        if i != j:\n",
    "                            train += other_split\n",
    "                    test = [] + split\n",
    "                    cvs.append((train, test))\n",
    "                return cvs\n",
    "                    \n",
    "            scores_for_point = []\n",
    "            estimator = clone(self.estimator)\n",
    "            estimator.set_params(**param_point)\n",
    "            for l_train, l_test in splits(list(X[\"listing_id\"].unique()), k=self.cv):                \n",
    "                X_train = X.query(\"listing_id in @l_train\").drop(columns=[\"listing_id\"])\n",
    "                X_test = X.query(\"listing_id in @l_test\").drop(columns=[\"listing_id\"])\n",
    "                y_train = y.query(\"listing_id in @l_train\").drop(columns=[\"listing_id\"])\n",
    "                y_test = y.query(\"listing_id in @l_test\").drop(columns=[\"listing_id\"])                \n",
    "                estimator.fit(X_train, y_train.values.ravel())\n",
    "                y_preds = estimator.predict(X_test)\n",
    "                f1_score_1 = f1_score(y_test, y_preds, pos_label=True)\n",
    "                f1_score_0 = f1_score(y_test, y_preds, pos_label=False)\n",
    "                score = min([f1_score_1, f1_score_0])\n",
    "                scores_for_point.append(score)\n",
    "                \n",
    "            mean_score = np.mean(scores_for_point)\n",
    "            if mean_score > self.best_estimator_scores_mean:\n",
    "                self.best_estimator_scores_mean = mean_score\n",
    "                self.best_estimator_scores_stdev = np.std(scores_for_point)\n",
    "                self.best_estimator = estimator\n",
    "                self.best_params = self.best_estimator.get_params()\n",
    "                self.best_score = self.best_estimator_scores_mean\n",
    "   \n",
    "            \n",
    "    def get_param_grid_points(self):\n",
    "        points = [{}]\n",
    "        for param, values in self.param_grid.items():\n",
    "            new_points = []\n",
    "            for point in points:\n",
    "                for value in values:                    \n",
    "                    new_point = point.copy()\n",
    "                    new_point[param]= value\n",
    "                    new_points.append(new_point)\n",
    "            points = new_points\n",
    "        return points\n",
    "    \n",
    "    def print_best(self):\n",
    "        print(\"Best score:\")\n",
    "        print(self.best_score)\n",
    "        print(\"Best params:\")\n",
    "        print(self.best_params)\n",
    "        print(\"Best estimator scores mean:\")\n",
    "        print(self.best_estimator_scores_mean)\n",
    "        print(\"Best estimator scores stdev:\")\n",
    "        print(self.best_estimator_scores_stdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cross_val_score(estimator, X, y):\n",
    "    def splits(array, k):\n",
    "        splits = []\n",
    "\n",
    "        for i in range(k):\n",
    "            split_length = math.ceil(len(array)/k)\n",
    "            split = []\n",
    "            for j in range(i * split_length, (i+1) * split_length):\n",
    "                if j < len(array):\n",
    "                    split.append(array[j])\n",
    "\n",
    "            splits.append(split)\n",
    "        cvs = []\n",
    "        for i, split in enumerate(splits):\n",
    "            train = []\n",
    "            for j, other_split in enumerate(splits):\n",
    "                if i != j:\n",
    "                    train += other_split\n",
    "            test = [] + split\n",
    "            cvs.append((train, test))\n",
    "        return cvs\n",
    "\n",
    "    scores_for_point = []\n",
    "    for l_train, l_test in splits(list(X[\"listing_id\"].unique()), k=5):                \n",
    "        X_train = X.query(\"listing_id in @l_train\").drop(columns=[\"listing_id\"])\n",
    "        X_test = X.query(\"listing_id in @l_test\").drop(columns=[\"listing_id\"])\n",
    "        y_train = y.query(\"listing_id in @l_train\").drop(columns=[\"listing_id\"])\n",
    "        y_test = y.query(\"listing_id in @l_test\").drop(columns=[\"listing_id\"])                \n",
    "        estimator.fit(X_train, y_train.values.ravel())\n",
    "        y_preds = estimator.predict(X_test)\n",
    "        f1_score_1 = f1_score(y_test, y_preds, pos_label=True)\n",
    "        f1_score_0 = f1_score(y_test, y_preds, pos_label=False)\n",
    "        score = min([f1_score_1, f1_score_0])\n",
    "        scores_for_point.append(score)\n",
    "\n",
    "    mean_score = np.mean(scores_for_point)\n",
    "    return mean_score\n",
    "\n",
    "import decimal\n",
    "\n",
    "def float_range(start, stop, step):\n",
    "    start = decimal.Decimal(start)\n",
    "    stop = decimal.Decimal(stop)\n",
    "    step = decimal.Decimal(step)\n",
    "    while (start < stop):\n",
    "        yield float(start)\n",
    "        start += step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using Bayesian optimization technique for choosing hyper parameters for each classifier. \n",
    "\n",
    "Please note that I am choosing the number of points explored in the parameter space to be 100 which can be considered as too small. However, keeping it small is essential to generate results in this notebook in timely manner for demonstration purpose. For real use case, it can be increased to 1000 or 10000 to get most optimal choice of hyperparameters from the hyperparameter space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Bayesian Optimization technique implemented in gp_minimize method of Scikit Optimize package to choose optimal hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_dtc(params):\n",
    "    clf = DecisionTreeClassifier(\n",
    "        max_depth = params[0],\n",
    "        min_samples_leaf = params[1],\n",
    "        max_features = params[2],\n",
    "        min_samples_split = params[3],\n",
    "        random_state = 42\n",
    "    )\n",
    "    score = my_cross_val_score(clf, X=X_train_sample, y=y_train_sample)\n",
    "    return -score\n",
    "start_time = time.time()\n",
    "dtc_opt_result = gp_minimize(\n",
    "    func=objective_dtc,\n",
    "    dimensions=[\n",
    "        (5, 30),\n",
    "        (1, 10),\n",
    "        (0.1, 1.0),\n",
    "        (2, 20)\n",
    "    ],\n",
    "    random_state=42\n",
    ")\n",
    "elapsed_time = (time.time() - start_time) / 60\n",
    "print('Elapsed computation time: {:.3f} mins'.format(elapsed_time))\n",
    "best_params_list_dtc = dtc_opt_result.x\n",
    "best_score_dtc = -dtc_opt_result.fun\n",
    "best_params_dtc = {\n",
    "    \"max_depth\": best_params_list_dtc[0],\n",
    "    \"min_samples_leaf\": best_params_list_dtc[1],\n",
    "    \"max_features\": best_params_list_dtc[2],\n",
    "    \"min_samples_split\": best_params_list_dtc[3]\n",
    "}\n",
    "print (\"Best score: \" + str(best_score_dtc))\n",
    "dtc = DecisionTreeClassifier()\n",
    "best_params_dtc[\"random_state\"] = 42\n",
    "dtc.set_params(**best_params_dtc)\n",
    "dtc.fit(X=X_train.drop(columns=[\"listing_id\"]), y=y_train.drop(columns=[\"listing_id\"]))\n",
    "pickle.dump(dtc, open('dtc_best.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s, best loss: ?]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-4a3739b44129>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m }\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mbest_params_ada\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspace_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mada_param_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective_ada\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mada_param_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Best params: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbest_params_ada\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    405\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[1;32m    406\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    225\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                         \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    842\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 844\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-123-4a3739b44129>\u001b[0m in \u001b[0;36mobjective_ada\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_cross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"score: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-121-ea733075a551>\u001b[0m in \u001b[0;36mmy_cross_val_score\u001b[0;34m(estimator, X, y)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"listing_id in @l_train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"listing_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"listing_id in @l_test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"listing_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mf1_score_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 random_state)\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# Early termination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \"\"\"\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective_ada(params):\n",
    "    clf = AdaBoostClassifier(DecisionTreeClassifier())\n",
    "    clf.set_params(**params)    \n",
    "    score = my_cross_val_score(clf, X=X_train_sample, y=y_train_sample)\n",
    "    print(params)\n",
    "    print(\"score: \" + str(score))\n",
    "    return -score\n",
    "ada_param_space = {\n",
    "    \"base_estimator__min_samples_leaf\": hp.choice(\"base_estimator__min_samples_leaf\", range(1,6,2)),\n",
    "    \"base_estimator__min_samples_split\": hp.choice(\"base_estimator__min_samples_split\", [2*x for x in range(1,11,2)]),\n",
    "    \"base_estimator__max_depth\": hp.choice(\"base_estimator__max_depth\", range(5, 31, 5)),\n",
    "    \"n_estimators\": hp.choice(\"n_estimators\", range(10, 101, 10)),\n",
    "    \"random_state\": hp.choice(\"random_state\", [42])\n",
    "}\n",
    "\n",
    "best_params_ada = space_eval(ada_param_space, fmin(objective_ada, ada_param_space, algo=tpe.suggest, max_evals=100))\n",
    "print (\"Best params: \")\n",
    "print (best_params_ada)\n",
    "ada = AdaBoostClassifier(DecisionTreeClassifier())\n",
    "ada.set_params(**best_params_ada)\n",
    "ada.fit(X=X_train.drop(columns=[\"listing_id\"]), y=y_train.drop(columns=[\"listing_id\"]))\n",
    "pickle.dump(ada, open('ada_best.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using custom Grid Search Cross validation method implemented by me to choose optimal hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9, 'n_estimators': 60}                 \n",
      "score: 0.696610497861299                             \n",
      "{'max_depth': 7, 'n_estimators': 100}                                           \n",
      "score: 0.6948120679057627                                                       \n",
      "{'max_depth': 7, 'n_estimators': 60}                                            \n",
      "score: 0.6932807018941117                                                       \n",
      "{'max_depth': 1, 'n_estimators': 50}                                            \n",
      "score: 0.6061870705911634                                                       \n",
      "{'max_depth': 7, 'n_estimators': 60}                                            \n",
      "score: 0.6947278164100691                                                     \n",
      "{'max_depth': 3, 'n_estimators': 90}                                          \n",
      "score: 0.6725557920558277                                                     \n",
      "{'max_depth': 4, 'n_estimators': 40}                                          \n",
      "score: 0.6699373813535116                                                     \n",
      "{'max_depth': 2, 'n_estimators': 30}                                          \n",
      "score: 0.636197137876488                                                      \n",
      "{'max_depth': 2, 'n_estimators': 80}                                          \n",
      "score: 0.6525755162886665                                                     \n",
      "{'max_depth': 6, 'n_estimators': 10}                                          \n",
      "score: 0.6546170817265949                                                     \n",
      "{'max_depth': 7, 'n_estimators': 60}                                           \n",
      "score: 0.6987483200489434                                                      \n",
      "{'max_depth': 1, 'n_estimators': 10}                                            \n",
      "score: 0.5128613046747                                                          \n",
      "{'max_depth': 3, 'n_estimators': 10}                                            \n",
      "score: 0.6136962692734462                                                       \n",
      "{'max_depth': 5, 'n_estimators': 30}                                            \n",
      "score: 0.6789626686351324                                                       \n",
      "{'max_depth': 9, 'n_estimators': 20}                                            \n",
      "score: 0.6831153183218172                                                       \n",
      "{'max_depth': 5, 'n_estimators': 100}                                           \n",
      "score: 0.6827306898645027                                                       \n",
      "{'max_depth': 8, 'n_estimators': 20}                                            \n",
      "score: 0.6763487649149716                                                       \n",
      "{'max_depth': 10, 'n_estimators': 50}                                           \n",
      "score: 0.6895090878707762                                                       \n",
      "{'max_depth': 8, 'n_estimators': 30}                                            \n",
      "score: 0.6938996833472649                                                       \n",
      "{'max_depth': 8, 'n_estimators': 100}                                           \n",
      "score: 0.6959067898891882                                                       \n",
      "{'max_depth': 9, 'n_estimators': 60}                                            \n",
      "score: 0.6939465288829241                                                       \n",
      "{'max_depth': 9, 'n_estimators': 70}                                            \n",
      "score: 0.694276047584633                                                        \n",
      "{'max_depth': 4, 'n_estimators': 60}                                              \n",
      "score: 0.6781584444439255                                                         \n",
      "{'max_depth': 6, 'n_estimators': 60}                                              \n",
      "score: 0.6967576937333435                                                       \n",
      "{'max_depth': 6, 'n_estimators': 60}                                            \n",
      "score: 0.6855232116095102                                                       \n",
      "{'max_depth': 6, 'n_estimators': 40}                                            \n",
      "score: 0.6825545244499925                                                       \n",
      "{'max_depth': 6, 'n_estimators': 90}                                            \n",
      "score: 0.6944884808428303                                                       \n",
      "{'max_depth': 7, 'n_estimators': 80}                                            \n",
      "score: 0.6907529957161328                                                       \n",
      "{'max_depth': 10, 'n_estimators': 60}                                           \n",
      "score: 0.6915082704637454                                                       \n",
      "{'max_depth': 6, 'n_estimators': 70}                                            \n",
      "score: 0.690307398608074                                                        \n",
      "{'max_depth': 7, 'n_estimators': 60}                                            \n",
      "score: 0.6932376300277361                                                       \n",
      "{'max_depth': 7, 'n_estimators': 60}                                            \n",
      "score: 0.6937056844054821                                                       \n",
      "{'max_depth': 1, 'n_estimators': 50}                                            \n",
      "score: 0.6061870705911634                                                       \n",
      "{'max_depth': 7, 'n_estimators': 60}                                            \n",
      "score: 0.6948882807057379                                                       \n",
      "{'max_depth': 3, 'n_estimators': 90}                                            \n",
      "score: 0.6722743674643681                                                       \n",
      "{'max_depth': 4, 'n_estimators': 40}                                            \n",
      "score: 0.6710042710975749                                                       \n",
      "{'max_depth': 2, 'n_estimators': 60}                                            \n",
      "score: 0.6499422802150298                                                       \n",
      "{'max_depth': 7, 'n_estimators': 70}                                            \n",
      "score: 0.6911784690620327                                                       \n",
      "{'max_depth': 6, 'n_estimators': 80}                                            \n",
      "score: 0.6870949443880222                                                       \n",
      "{'max_depth': 5, 'n_estimators': 20}                                            \n",
      "score: 0.6691085398050814                                                       \n",
      "{'max_depth': 2, 'n_estimators': 100}                                           \n",
      "score: 0.6603499896583035                                                       \n",
      "{'max_depth': 10, 'n_estimators': 60}                                           \n",
      "score: 0.693476713620731                                                        \n",
      "{'max_depth': 1, 'n_estimators': 10}                                            \n",
      "score: 0.5128613046747                                                          \n",
      "{'max_depth': 3, 'n_estimators': 50}                                            \n",
      "score: 0.6594489932688905                                                       \n",
      "{'max_depth': 7, 'n_estimators': 30}                                            \n",
      "score: 0.6865652512886156                                                       \n",
      "{'max_depth': 6, 'n_estimators': 90}                                            \n",
      "score: 0.6863677794191309                                                       \n",
      "{'max_depth': 4, 'n_estimators': 40}                                            \n",
      "score: 0.6713250978009423                                                       \n",
      "{'max_depth': 5, 'n_estimators': 80}                                            \n",
      "score: 0.6898696555413234                                                       \n",
      "{'max_depth': 8, 'n_estimators': 20}                                            \n",
      "score: 0.6816444908886291                                                       \n",
      "{'max_depth': 9, 'n_estimators': 60}                                            \n",
      "score: 0.6984565479473609                                                       \n",
      "{'max_depth': 9, 'n_estimators': 10}                                            \n",
      "score: 0.6623612798083901                                                       \n",
      "{'max_depth': 9, 'n_estimators': 100}                                           \n",
      "score: 0.6992490864442543                                                       \n",
      "{'max_depth': 9, 'n_estimators': 100}                                           \n",
      "score: 0.6991385892095446                                                       \n",
      "{'max_depth': 9, 'n_estimators': 100}                                           \n",
      "score: 0.6928394797776051                                                       \n",
      "{'max_depth': 9, 'n_estimators': 100}                                           \n",
      "score: 0.6989523568561148                                                       \n",
      "{'max_depth': 9, 'n_estimators': 100}                                           \n",
      "score: 0.6972917676776165                                                       \n",
      "{'max_depth': 9, 'n_estimators': 100}                                           \n",
      "score: 0.6962930160259964                                                       \n",
      "{'max_depth': 9, 'n_estimators': 100}                                           \n",
      "score: 0.702651193164746                                                        \n",
      "{'max_depth': 9, 'n_estimators': 100}                                           \n",
      "score: 0.6962765069091535                                                      \n",
      "{'max_depth': 10, 'n_estimators': 100}                                         \n",
      "score: 0.6953972147485167                                                      \n",
      "{'max_depth': 1, 'n_estimators': 30}                                           \n",
      "score: 0.5930843244692744                                                      \n",
      "{'max_depth': 2, 'n_estimators': 100}                                          \n",
      "score: 0.6602887092449651                                                      \n",
      "{'max_depth': 3, 'n_estimators': 70}                                           \n",
      "score: 0.6692544893298167                                                      \n",
      "{'max_depth': 9, 'n_estimators': 50}                                           \n",
      "score: 0.6943377482836728                                                      \n",
      "{'max_depth': 8, 'n_estimators': 100}                                          \n",
      "score: 0.7019078558339565                                                      \n",
      "{'max_depth': 8, 'n_estimators': 100}                                          \n",
      "score: 0.6984876872771745                                                      \n",
      "{'max_depth': 4, 'n_estimators': 100}                                          \n",
      "score: 0.6794410328397736                                                      \n",
      "{'max_depth': 5, 'n_estimators': 100}                                          \n",
      "score: 0.6821357274504464                                                      \n",
      "{'max_depth': 8, 'n_estimators': 100}                                          \n",
      "score: 0.7024805512060454                                                      \n",
      "{'max_depth': 8, 'n_estimators': 90}                                           \n",
      "score: 0.7032176573345569                                                      \n",
      "{'max_depth': 8, 'n_estimators': 90}                                            \n",
      "score: 0.6966690866286557                                                       \n",
      "{'max_depth': 8, 'n_estimators': 90}                                            \n",
      "score: 0.7060739815654763                                                       \n",
      "{'max_depth': 8, 'n_estimators': 90}                                            \n",
      "score: 0.6961331379338236                                                       \n",
      "{'max_depth': 8, 'n_estimators': 90}                                            \n",
      "score: 0.699970638065845                                                        \n",
      "{'max_depth': 8, 'n_estimators': 90}                                            \n",
      "score: 0.6977446303766047                                                       \n",
      "{'max_depth': 8, 'n_estimators': 90}                                            \n",
      "score: 0.7023659418157128                                                       \n",
      "{'max_depth': 8, 'n_estimators': 90}                                            \n",
      "score: 0.6991378721831261                                                       \n",
      "{'max_depth': 10, 'n_estimators': 90}                                           \n",
      "score: 0.698451501914191                                                        \n",
      "{'max_depth': 1, 'n_estimators': 40}                                            \n",
      "score: 0.6051340687577194                                                       \n",
      "{'max_depth': 2, 'n_estimators': 20}                                            \n",
      "score: 0.6340440149269749                                                       \n",
      "{'max_depth': 3, 'n_estimators': 80}                                            \n",
      "score: 0.673407053205357                                                        \n",
      "{'max_depth': 8, 'n_estimators': 90}                                            \n",
      "score: 0.7007400377713556                                                       \n",
      "{'max_depth': 4, 'n_estimators': 10}                                            \n",
      "score: 0.6400019416341537                                                       \n",
      "{'max_depth': 5, 'n_estimators': 70}                                            \n",
      "score: 0.686955414491775                                                        \n",
      "{'max_depth': 8, 'n_estimators': 30}                                            \n",
      "score: 0.69091870773548                                                         \n",
      "{'max_depth': 10, 'n_estimators': 90}                                           \n",
      "score: 0.6970297469189034                                                       \n",
      "{'max_depth': 1, 'n_estimators': 50}                                            \n",
      "score: 0.6061870705911634                                                       \n",
      "{'max_depth': 8, 'n_estimators': 40}                                            \n",
      "score: 0.6995235628126588                                                       \n",
      "{'max_depth': 2, 'n_estimators': 90}                                            \n",
      "score: 0.6536663161752064                                                       \n",
      "{'max_depth': 3, 'n_estimators': 20}                                            \n",
      "score: 0.6468909431823137                                                       \n",
      "{'max_depth': 6, 'n_estimators': 80}                                            \n",
      "score: 0.6896050360769275                                                       \n",
      "{'max_depth': 7, 'n_estimators': 10}                                            \n",
      "score: 0.6621410788923144                                                       \n",
      "{'max_depth': 4, 'n_estimators': 90}                                            \n",
      "score: 0.6814231452291949                                                       \n",
      "{'max_depth': 5, 'n_estimators': 30}                                            \n",
      "score: 0.6801582064268755                                                       \n",
      "{'max_depth': 8, 'n_estimators': 50}                                            \n",
      "score: 0.7004698789206653                                                       \n",
      "{'max_depth': 9, 'n_estimators': 70}                                            \n",
      "score: 0.6925187578590677                                                       \n",
      "{'max_depth': 8, 'n_estimators': 90}                                            \n",
      "score: 0.69744783137768                                                         \n",
      "{'max_depth': 10, 'n_estimators': 40}                                           \n",
      "score: 0.6909498055232038                                                       \n",
      "{'max_depth': 1, 'n_estimators': 80}                                            \n",
      "score: 0.61721818054798                                                         \n",
      "{'max_depth': 6, 'n_estimators': 20}                                            \n",
      "score: 0.6699417993571118                                                       \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [57:18<00:00, 26.13s/it, best loss: -0.7060739815654763]\n",
      "Best params: \n",
      "{'max_depth': 8, 'n_estimators': 90}\n"
     ]
    }
   ],
   "source": [
    "def objective_gb(params):\n",
    "    clf = GradientBoostingClassifier()\n",
    "    clf.set_params(**params)    \n",
    "    score = my_cross_val_score(clf, X=X_train_sample, y=y_train_sample)\n",
    "    print(params)\n",
    "    print(\"score: \" + str(score))\n",
    "    return -score\n",
    "\n",
    "gb_param_space = {    \n",
    "    \"max_depth\": hp.choice(\"max_depth\", range(1, 11, 1)),\n",
    "    \"n_estimators\": hp.choice(\"n_estimators\", range(10, 101, 10)),\n",
    "    \"random_state\": hp.choice(\"random_state\", [42])\n",
    "}\n",
    "\n",
    "best_params_gb = space_eval(gb_param_space, fmin(objective_gb, gb_param_space, algo=tpe.suggest, max_evals=100))\n",
    "print (\"Best params: \")\n",
    "print (best_params_gb)\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.set_params(**best_params_gb)\n",
    "gb.fit(X=X_train.drop(columns=[\"listing_id\"]), y=y_train.drop(columns=[\"listing_id\"]))\n",
    "pickle.dump(gb, open('gb_best.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 15, 'min_samples_leaf': 5, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.6852563051659241                            \n",
      "{'max_depth': 21, 'min_samples_leaf': 1, 'n_estimators': 40, 'random_state': 42}\n",
      "score: 0.6888692813185899                                                      \n",
      "{'max_depth': 9, 'min_samples_leaf': 9, 'n_estimators': 80, 'random_state': 42}\n",
      "score: 0.6667019428150623                                                      \n",
      "{'max_depth': 13, 'min_samples_leaf': 9, 'n_estimators': 30, 'random_state': 42}\n",
      "score: 0.6699654945138891                                                      \n",
      "{'max_depth': 25, 'min_samples_leaf': 3, 'n_estimators': 50, 'random_state': 42}\n",
      "score: 0.69761761647907                                                        \n",
      "{'max_depth': 5, 'min_samples_leaf': 3, 'n_estimators': 80, 'random_state': 42}\n",
      "score: 0.6382559003697867                                                    \n",
      "{'max_depth': 19, 'min_samples_leaf': 9, 'n_estimators': 90, 'random_state': 42}\n",
      "score: 0.6880699193255853                                                    \n",
      "{'max_depth': 9, 'min_samples_leaf': 5, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.668724959225306                                                     \n",
      "{'max_depth': 9, 'min_samples_leaf': 5, 'n_estimators': 10, 'random_state': 42}\n",
      "score: 0.6432600189865006                                                    \n",
      "{'max_depth': 29, 'min_samples_leaf': 7, 'n_estimators': 80, 'random_state': 42}\n",
      "score: 0.6952919321712219                                                    \n",
      "{'max_depth': 9, 'min_samples_leaf': 9, 'n_estimators': 50, 'random_state': 42}\n",
      "score: 0.6607591138810076                                                     \n",
      "{'max_depth': 11, 'min_samples_leaf': 3, 'n_estimators': 50, 'random_state': 42}\n",
      "score: 0.6815928556540743                                                     \n",
      "{'max_depth': 9, 'min_samples_leaf': 9, 'n_estimators': 50, 'random_state': 42}\n",
      "score: 0.6607591138810076                                                     \n",
      "{'max_depth': 13, 'min_samples_leaf': 1, 'n_estimators': 60, 'random_state': 42}\n",
      "score: 0.6896844909147425                                                     \n",
      "{'max_depth': 11, 'min_samples_leaf': 5, 'n_estimators': 70, 'random_state': 42}\n",
      "score: 0.6711778098501717                                                     \n",
      "{'max_depth': 17, 'min_samples_leaf': 5, 'n_estimators': 20, 'random_state': 42}\n",
      "score: 0.6699532362677194                                                     \n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'n_estimators': 80, 'random_state': 42}\n",
      "score: 0.6352466843027178                                                     \n",
      "{'max_depth': 15, 'min_samples_leaf': 7, 'n_estimators': 50, 'random_state': 42}\n",
      "score: 0.6823380518902541                                                     \n",
      "{'max_depth': 17, 'min_samples_leaf': 5, 'n_estimators': 90, 'random_state': 42}\n",
      "score: 0.676124513195639                                                      \n",
      "{'max_depth': 19, 'min_samples_leaf': 1, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.6956152322322944                                                     \n",
      "{'max_depth': 25, 'min_samples_leaf': 3, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.6989061393401956                                                     \n",
      "{'max_depth': 25, 'min_samples_leaf': 3, 'n_estimators': 60, 'random_state': 42}\n",
      "score: 0.6945105021304078                                                       \n",
      "{'max_depth': 25, 'min_samples_leaf': 3, 'n_estimators': 10, 'random_state': 42}\n",
      "score: 0.6596641455023652                                                       \n",
      "{'max_depth': 23, 'min_samples_leaf': 3, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.70043923626138                                                         \n",
      "{'max_depth': 23, 'min_samples_leaf': 3, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.70043923626138                                                       \n",
      "{'max_depth': 23, 'min_samples_leaf': 3, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.70043923626138                                                       \n",
      "{'max_depth': 23, 'min_samples_leaf': 3, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.70043923626138                                                       \n",
      "{'max_depth': 23, 'min_samples_leaf': 3, 'n_estimators': 70, 'random_state': 42}\n",
      "score: 0.6964897070774123                                                     \n",
      "{'max_depth': 7, 'min_samples_leaf': 7, 'n_estimators': 40, 'random_state': 42}\n",
      "score: 0.6470944528943077                                                     \n",
      "{'max_depth': 27, 'min_samples_leaf': 3, 'n_estimators': 30, 'random_state': 42}\n",
      "score: 0.6839789925496917                                                     \n",
      "{'max_depth': 23, 'min_samples_leaf': 3, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.70043923626138                                                       \n",
      "{'max_depth': 21, 'min_samples_leaf': 3, 'n_estimators': 20, 'random_state': 42}\n",
      "score: 0.674226222206015                                                      \n",
      "{'max_depth': 23, 'min_samples_leaf': 7, 'n_estimators': 40, 'random_state': 42}\n",
      "score: 0.6849499509234453                                                     \n",
      "{'max_depth': 23, 'min_samples_leaf': 3, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.70043923626138                                                       \n",
      "{'max_depth': 29, 'min_samples_leaf': 1, 'n_estimators': 30, 'random_state': 42}\n",
      "score: 0.6820610801825394                                                     \n",
      "{'max_depth': 7, 'min_samples_leaf': 3, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.6619977296189363                                                     \n",
      "{'max_depth': 27, 'min_samples_leaf': 3, 'n_estimators': 90, 'random_state': 42}\n",
      "score: 0.6963183679481252                                                     \n",
      "{'max_depth': 15, 'min_samples_leaf': 9, 'n_estimators': 10, 'random_state': 42}\n",
      "score: 0.6621678174913541                                                     \n",
      "{'max_depth': 23, 'min_samples_leaf': 7, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.6885870291021324                                                     \n",
      "{'max_depth': 13, 'min_samples_leaf': 3, 'n_estimators': 60, 'random_state': 42}\n",
      "score: 0.6768985669962547                                                     \n",
      "{'max_depth': 21, 'min_samples_leaf': 9, 'n_estimators': 20, 'random_state': 42}\n",
      "score: 0.6736815925905242                                                     \n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'n_estimators': 70, 'random_state': 42}\n",
      "score: 0.6372638750454321                                                     \n",
      "{'max_depth': 19, 'min_samples_leaf': 5, 'n_estimators': 40, 'random_state': 42}\n",
      "score: 0.6859294651908788                                                     \n",
      "{'max_depth': 29, 'min_samples_leaf': 3, 'n_estimators': 80, 'random_state': 42}\n",
      "score: 0.698249295760071                                                      \n",
      "{'max_depth': 11, 'min_samples_leaf': 9, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.6706316418033408                                                     \n",
      "{'max_depth': 23, 'min_samples_leaf': 3, 'n_estimators': 30, 'random_state': 42}\n",
      "score: 0.6836328767063764                                                     \n",
      "{'max_depth': 13, 'min_samples_leaf': 7, 'n_estimators': 10, 'random_state': 42}\n",
      "score: 0.656612905651967                                                      \n",
      "{'max_depth': 17, 'min_samples_leaf': 5, 'n_estimators': 90, 'random_state': 42}\n",
      "score: 0.676124513195639                                                      \n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.6887456868895446                                                     \n",
      "{'max_depth': 9, 'min_samples_leaf': 9, 'n_estimators': 80, 'random_state': 42}\n",
      "score: 0.6667019428150623                                                     \n",
      "{'max_depth': 5, 'min_samples_leaf': 3, 'n_estimators': 60, 'random_state': 42}\n",
      "score: 0.6317495658284453                                                     \n",
      "{'max_depth': 7, 'min_samples_leaf': 5, 'n_estimators': 50, 'random_state': 42}\n",
      "score: 0.6484341765711392                                                     \n",
      "{'max_depth': 23, 'min_samples_leaf': 3, 'n_estimators': 70, 'random_state': 42}\n",
      "score: 0.6964897070774123                                                     \n",
      "{'max_depth': 27, 'min_samples_leaf': 1, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.7013561681155431                                                     \n",
      "{'max_depth': 11, 'min_samples_leaf': 1, 'n_estimators': 20, 'random_state': 42}\n",
      "score: 0.6642519314185265                                                       \n",
      "{'max_depth': 27, 'min_samples_leaf': 1, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.7013561681155431                                                       \n",
      "{'max_depth': 27, 'min_samples_leaf': 1, 'n_estimators': 50, 'random_state': 42}\n",
      "score: 0.6929449385794946                                                       \n",
      "{'max_depth': 27, 'min_samples_leaf': 1, 'n_estimators': 90, 'random_state': 42}\n",
      "score: 0.7002591668134803                                                       \n",
      "{'max_depth': 27, 'min_samples_leaf': 1, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.7013561681155431                                                       \n",
      "{'max_depth': 27, 'min_samples_leaf': 1, 'n_estimators': 10, 'random_state': 42}\n",
      "score: 0.6486421006494172                                                       \n",
      "{'max_depth': 27, 'min_samples_leaf': 1, 'n_estimators': 40, 'random_state': 42}\n",
      "score: 0.6943338356111951                                                       \n",
      "{'max_depth': 27, 'min_samples_leaf': 1, 'n_estimators': 30, 'random_state': 42}\n",
      "score: 0.6869585960139377                                                       \n",
      "{'max_depth': 19, 'min_samples_leaf': 1, 'n_estimators': 80, 'random_state': 42}\n",
      "score: 0.6964091508876519                                                       \n",
      "{'max_depth': 21, 'min_samples_leaf': 1, 'n_estimators': 60, 'random_state': 42}\n",
      "score: 0.6929528897326096                                                       \n",
      "{'max_depth': 17, 'min_samples_leaf': 1, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.6900752205632976                                                       \n",
      "{'max_depth': 27, 'min_samples_leaf': 1, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.7013561681155431                                                       \n",
      "{'max_depth': 27, 'min_samples_leaf': 1, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.7013561681155431                                                       \n",
      "{'max_depth': 27, 'min_samples_leaf': 1, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.7013561681155431                                                       \n",
      "{'max_depth': 27, 'min_samples_leaf': 1, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.7013561681155431                                                       \n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.6905784246528973                                                       \n",
      "{'max_depth': 27, 'min_samples_leaf': 1, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.7013561681155431                                                       \n",
      "{'max_depth': 9, 'min_samples_leaf': 1, 'n_estimators': 70, 'random_state': 42} \n",
      "score: 0.6648451520308387                                                       \n",
      "{'max_depth': 27, 'min_samples_leaf': 7, 'n_estimators': 20, 'random_state': 42}\n",
      "score: 0.6721347995030333                                                       \n",
      "{'max_depth': 29, 'min_samples_leaf': 1, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.6941179360396078                                                       \n",
      "{'max_depth': 15, 'min_samples_leaf': 5, 'n_estimators': 50, 'random_state': 42}\n",
      "score: 0.6776900236781449                                                       \n",
      "{'max_depth': 13, 'min_samples_leaf': 9, 'n_estimators': 40, 'random_state': 42}\n",
      "score: 0.6712297279052207                                                       \n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.6414392674979024                                                       \n",
      "{'max_depth': 7, 'min_samples_leaf': 7, 'n_estimators': 90, 'random_state': 42} \n",
      "score: 0.6511026880084654                                                       \n",
      "{'max_depth': 27, 'min_samples_leaf': 1, 'n_estimators': 10, 'random_state': 42}\n",
      "score: 0.6486421006494172                                                       \n",
      "{'max_depth': 19, 'min_samples_leaf': 1, 'n_estimators': 30, 'random_state': 42}\n",
      "score: 0.6827785179838337                                                       \n",
      "{'max_depth': 25, 'min_samples_leaf': 5, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.6938749701071079                                                       \n",
      "{'max_depth': 21, 'min_samples_leaf': 9, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.6846948254365025                                                       \n",
      "{'max_depth': 11, 'min_samples_leaf': 1, 'n_estimators': 60, 'random_state': 42}\n",
      "score: 0.6772707058814479                                                       \n",
      "{'max_depth': 17, 'min_samples_leaf': 7, 'n_estimators': 80, 'random_state': 42}\n",
      "score: 0.6809441259096062                                                       \n",
      "{'max_depth': 27, 'min_samples_leaf': 1, 'n_estimators': 70, 'random_state': 42}\n",
      "score: 0.6966615710923074                                                       \n",
      "{'max_depth': 29, 'min_samples_leaf': 1, 'n_estimators': 20, 'random_state': 42}\n",
      "score: 0.6700997787951157                                                       \n",
      "{'max_depth': 9, 'min_samples_leaf': 5, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.668724959225306                                                        \n",
      "{'max_depth': 27, 'min_samples_leaf': 9, 'n_estimators': 50, 'random_state': 42}\n",
      "score: 0.6854686563530945                                                       \n",
      "{'max_depth': 13, 'min_samples_leaf': 1, 'n_estimators': 40, 'random_state': 42}\n",
      "score: 0.6892111908677293                                                       \n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'n_estimators': 90, 'random_state': 42}\n",
      "score: 0.688331341573124                                                        \n",
      "{'max_depth': 5, 'min_samples_leaf': 7, 'n_estimators': 10, 'random_state': 42} \n",
      "score: 0.6217607832466402                                                       \n",
      "{'max_depth': 7, 'min_samples_leaf': 1, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.656520442960076                                                        \n",
      "{'max_depth': 27, 'min_samples_leaf': 1, 'n_estimators': 30, 'random_state': 42}\n",
      "score: 0.6869585960139377                                                       \n",
      "{'max_depth': 11, 'min_samples_leaf': 5, 'n_estimators': 60, 'random_state': 42}\n",
      "score: 0.6724210086860745                                                       \n",
      "{'max_depth': 19, 'min_samples_leaf': 9, 'n_estimators': 80, 'random_state': 42}\n",
      "score: 0.6868009107170981                                                       \n",
      "{'max_depth': 27, 'min_samples_leaf': 1, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.7013561681155431                                                       \n",
      "{'max_depth': 21, 'min_samples_leaf': 1, 'n_estimators': 70, 'random_state': 42}\n",
      "score: 0.6956185869567408                                                       \n",
      "{'max_depth': 17, 'min_samples_leaf': 7, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.6799087430455091                                                       \n",
      "{'max_depth': 27, 'min_samples_leaf': 1, 'n_estimators': 20, 'random_state': 42}\n",
      "score: 0.675633230253472                                                        \n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'n_estimators': 100, 'random_state': 42}\n",
      "score: 0.6905784246528973                                                       \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [09:33<00:00,  7.21s/it, best loss: -0.7013561681155431]\n",
      "Best params: \n",
      "{'max_depth': 27, 'min_samples_leaf': 1, 'n_estimators': 100, 'random_state': 42}\n",
      "Elapsed computation time: 11.302 mins\n"
     ]
    }
   ],
   "source": [
    "def objective_rf(params):\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.set_params(**params)\n",
    "    score = my_cross_val_score(clf, X=X_train_sample, y=y_train_sample)\n",
    "    print(params)\n",
    "    print(\"score: \" + str(score))\n",
    "    return -score\n",
    "rf_param_space = {\n",
    "    \"min_samples_leaf\": hp.choice(\"min_samples_leaf\", range(1, 10, 2)),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", range(5, 31, 2)),\n",
    "    \"n_estimators\": hp.choice(\"n_estimators\", range(10, 101, 10)),\n",
    "    \"random_state\": hp.choice(\"random_state\", [42])\n",
    "}\n",
    "start_time = time.time()\n",
    "best_params_rf = space_eval(rf_param_space, fmin(objective_rf, rf_param_space, algo=tpe.suggest, max_evals=100))\n",
    "print (\"Best params: \")\n",
    "print (best_params_rf)\n",
    "rf = RandomForestClassifier()\n",
    "rf.set_params(**best_params_gb)\n",
    "rf.fit(X=X_train.drop(columns=[\"listing_id\"]), y=y_train.drop(columns=[\"listing_id\"]))\n",
    "pickle.dump(rf, open('rf_best.pkl', 'wb'))\n",
    "elapsed_time = (time.time() - start_time) / 60\n",
    "print('Elapsed computation time: {:.3f} mins'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction & Model Evaluation of Ensemble Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest f1-score: 0.6723685549898285\n",
      "Model: Gradient Boost f1-score: 0.7109701838759012\n",
      "Model: Ada Boost f1-score: 0.6888888158539574\n",
      "Model: Single Decision Tree f1-score: 0.6422772986026057\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Random Forest\": \"rf_best.pkl\",\n",
    "    \"Gradient Boost\": \"gb_best.pkl\",\n",
    "    \"Ada Boost\": \"ada_best.pkl\",\n",
    "    \"Single Decision Tree\": \"dtc_best.pkl\"\n",
    "}\n",
    "for model_name in models.keys():\n",
    "    model_file_name = models[model_name]\n",
    "    model = pickle.load(open(model_file_name, 'rb'))\n",
    "    y_preds = model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_preds, average=\"macro\")\n",
    "    print (\"Model: \" + model_name + \" f1-score: \" + str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: Random Forest\n",
      "Best Params: \n",
      "{   'bootstrap': True,\n",
      "    'class_weight': None,\n",
      "    'criterion': 'gini',\n",
      "    'max_depth': 8,\n",
      "    'max_features': 'auto',\n",
      "    'max_leaf_nodes': None,\n",
      "    'min_impurity_decrease': 0.0,\n",
      "    'min_impurity_split': None,\n",
      "    'min_samples_leaf': 1,\n",
      "    'min_samples_split': 2,\n",
      "    'min_weight_fraction_leaf': 0.0,\n",
      "    'n_estimators': 90,\n",
      "    'n_jobs': None,\n",
      "    'oob_score': False,\n",
      "    'random_state': 42,\n",
      "    'verbose': 0,\n",
      "    'warm_start': False}\n",
      "Top 10 Feature importances: \n",
      "[   ('number_of_reviews', 0.0796338964159641),\n",
      "    ('bed_type_nan', 0.0757061779373083),\n",
      "    ('cancellation_policy_strict', 0.048751677138062256),\n",
      "    ('review_scores_value', 0.04793682961312262),\n",
      "    ('maximum_nights', 0.0432464785877162),\n",
      "    ('price_calendar', 0.04057089377128203),\n",
      "    ('review_scores_accuracy', 0.031324091332953684),\n",
      "    ('review_scores_rating', 0.030998062615129073),\n",
      "    ('cancellation_policy_moderate', 0.029669653701363093),\n",
      "    ('month_October', 0.02620819574796239),\n",
      "    ('reviews_per_month', 0.02573099261928168),\n",
      "    ('amenity_Buzzer/Wireless Intercom', 0.01667239469079671),\n",
      "    ('review_scores_communication', 0.015517357030632839),\n",
      "    ('review_scores_location', 0.014477297737897079),\n",
      "    ('property_type_Guesthouse', 0.014170378906733047),\n",
      "    ('amenity_Essentials', 0.014042813692981486),\n",
      "    ('minimum_nights', 0.01370307287121381),\n",
      "    ('accommodates', 0.012701614740397764),\n",
      "    ('neighbourhood_cleansed_Chinatown', 0.011443809774559168),\n",
      "    ('guests_included', 0.011028155970959398)]\n",
      "\n",
      "Model: Gradient Boost\n",
      "Best Params: \n",
      "{   'criterion': 'friedman_mse',\n",
      "    'init': None,\n",
      "    'learning_rate': 0.1,\n",
      "    'loss': 'deviance',\n",
      "    'max_depth': 8,\n",
      "    'max_features': None,\n",
      "    'max_leaf_nodes': None,\n",
      "    'min_impurity_decrease': 0.0,\n",
      "    'min_impurity_split': None,\n",
      "    'min_samples_leaf': 1,\n",
      "    'min_samples_split': 2,\n",
      "    'min_weight_fraction_leaf': 0.0,\n",
      "    'n_estimators': 90,\n",
      "    'n_iter_no_change': None,\n",
      "    'presort': 'auto',\n",
      "    'random_state': 42,\n",
      "    'subsample': 1.0,\n",
      "    'tol': 0.0001,\n",
      "    'validation_fraction': 0.1,\n",
      "    'verbose': 0,\n",
      "    'warm_start': False}\n",
      "Top 10 Feature importances: \n",
      "[   ('price_calendar', 0.11944038587800429),\n",
      "    ('number_of_reviews', 0.07836321545554639),\n",
      "    ('reviews_per_month', 0.0515544505422136),\n",
      "    ('maximum_nights', 0.044588984422762656),\n",
      "    ('bed_type_nan', 0.034316888635951184),\n",
      "    ('minimum_nights', 0.029402906533010694),\n",
      "    ('month_October', 0.025745642816731636),\n",
      "    ('cancellation_policy_strict', 0.025097931677751786),\n",
      "    ('month_November', 0.024896961654449334),\n",
      "    ('review_scores_rating', 0.022330299303799723),\n",
      "    ('property_type_nan', 0.0192244105488164),\n",
      "    ('guests_included', 0.01714618679007291),\n",
      "    ('accommodates', 0.01709692820594586),\n",
      "    ('amenity_Buzzer/Wireless Intercom', 0.015588497825960054),\n",
      "    ('property_type_Guesthouse', 0.014633333307126479),\n",
      "    ('bedrooms', 0.012542231797717832),\n",
      "    ('review_scores_value', 0.012118071780820881),\n",
      "    ('bathrooms', 0.011492351988181581),\n",
      "    ('month_May', 0.011313521035697851),\n",
      "    ('amenity_Essentials', 0.010899033058765365)]\n",
      "\n",
      "Model: Ada Boost\n",
      "Best Params: \n",
      "{   'algorithm': 'SAMME.R',\n",
      "    'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=25,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'),\n",
      "    'base_estimator__class_weight': None,\n",
      "    'base_estimator__criterion': 'gini',\n",
      "    'base_estimator__max_depth': 25,\n",
      "    'base_estimator__max_features': None,\n",
      "    'base_estimator__max_leaf_nodes': None,\n",
      "    'base_estimator__min_impurity_decrease': 0.0,\n",
      "    'base_estimator__min_impurity_split': None,\n",
      "    'base_estimator__min_samples_leaf': 1,\n",
      "    'base_estimator__min_samples_split': 2,\n",
      "    'base_estimator__min_weight_fraction_leaf': 0.0,\n",
      "    'base_estimator__presort': False,\n",
      "    'base_estimator__random_state': None,\n",
      "    'base_estimator__splitter': 'best',\n",
      "    'learning_rate': 1.0,\n",
      "    'n_estimators': 90,\n",
      "    'random_state': 42}\n",
      "Top 10 Feature importances: \n",
      "[   ('accommodates', nan),\n",
      "    ('bathrooms', nan),\n",
      "    ('bedrooms', nan),\n",
      "    ('beds', nan),\n",
      "    ('guests_included', nan),\n",
      "    ('minimum_nights', nan),\n",
      "    ('maximum_nights', nan),\n",
      "    ('review_scores_rating', nan),\n",
      "    ('review_scores_accuracy', nan),\n",
      "    ('review_scores_cleanliness', nan),\n",
      "    ('review_scores_checkin', nan),\n",
      "    ('review_scores_communication', nan),\n",
      "    ('review_scores_location', nan),\n",
      "    ('review_scores_value', nan),\n",
      "    ('reviews_per_month', nan),\n",
      "    ('number_of_reviews', nan),\n",
      "    ('amenity_Wireless Internet', 0.00044130642777644207),\n",
      "    ('amenity_Kitchen', 0.0003561371764300164),\n",
      "    ('amenity_TV', 0.0002832144617370713),\n",
      "    ('amenity_Free Parking on Premises', nan)]\n",
      "\n",
      "Model: Single Decision Tree\n",
      "Best Params: \n",
      "{   'class_weight': None,\n",
      "    'criterion': 'gini',\n",
      "    'max_depth': 26,\n",
      "    'max_features': 0.7783427928319715,\n",
      "    'max_leaf_nodes': None,\n",
      "    'min_impurity_decrease': 0.0,\n",
      "    'min_impurity_split': None,\n",
      "    'min_samples_leaf': 10,\n",
      "    'min_samples_split': 20,\n",
      "    'min_weight_fraction_leaf': 0.0,\n",
      "    'presort': False,\n",
      "    'random_state': 42,\n",
      "    'splitter': 'best'}\n",
      "Top 10 Feature importances: \n",
      "[   ('price_calendar', 0.1280544151967343),\n",
      "    ('number_of_reviews', 0.05073457114347813),\n",
      "    ('reviews_per_month', 0.03460100637487817),\n",
      "    ('month_October', 0.031055684718235346),\n",
      "    ('review_scores_value', 0.03098266715696887),\n",
      "    ('month_November', 0.027793080632863152),\n",
      "    ('month_May', 0.027418358170158898),\n",
      "    ('maximum_nights', 0.025150304303178203),\n",
      "    ('minimum_nights', 0.020710112074985187),\n",
      "    ('bed_type_nan', 0.018605905719956465),\n",
      "    ('review_scores_rating', 0.0182426990710552),\n",
      "    ('cancellation_policy_strict', 0.017654940021286737),\n",
      "    ('month_August', 0.016158161557358875),\n",
      "    ('accommodates', 0.015326839903079396),\n",
      "    ('guests_included', 0.014906848059204066),\n",
      "    ('week_of_month', 0.014594276149392023),\n",
      "    ('bedrooms', 0.014198758862697721),\n",
      "    ('month_February', 0.014026890371707677),\n",
      "    ('review_scores_cleanliness', 0.013323085302506622),\n",
      "    ('amenity_Buzzer/Wireless Intercom', 0.013239610600764196)]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "def print_top10(feature_names, clf, class_labels):\n",
    "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "    pp.pprint(sorted(list(zip(feature_names, clf.feature_importances_)), key=lambda x: x[1], \n",
    "reverse=True)[:20])\n",
    "\n",
    "for model_name in models.keys():\n",
    "    model_file_name = models[model_name]\n",
    "    model = pickle.load(open(model_file_name, 'rb'))\n",
    "    print(\"\\nModel: \" + model_name)\n",
    "    print(\"Best Params: \")\n",
    "    pp.pprint(model.get_params())\n",
    "    print(\"Top 10 Feature importances: \")\n",
    "    print_top10(X_train_sample.columns, model, model.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import decimal\n",
    "\n",
    "def float_range(start, stop, step):\n",
    "    start = decimal.Decimal(start)\n",
    "    stop = decimal.Decimal(stop)\n",
    "    step = decimal.Decimal(step)\n",
    "    while (start < stop):\n",
    "        yield float(start)\n",
    "        start += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = list(float_range('0.025', '1', '0.025'))\n",
    "revenue_by_threshold= pd.DataFrame({\"revenue\": 0}, index=thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_revenue_at_tuned_price(row, threshold, clf):\n",
    "    current_price = row[\"price_calendar\"]\n",
    "#     print(\"price_calendar: \" + str(current_price))\n",
    "    df = pd.DataFrame(data=row.to_dict(), index=[0])\n",
    "    prob_booked = clf.predict_proba(df)[0][0]\n",
    "#     print (\"probability of booked at price_calendar: \" + str(prob_booked))\n",
    "    if (prob_booked < threshold):\n",
    "#         print (\"Will try with reduced the price\")\n",
    "        trial_price = current_price\n",
    "        saved_trial_price = None\n",
    "        steps_in_trap = 0\n",
    "        while (prob_booked < threshold and trial_price > 10):\n",
    "            saved_trial_price = trial_price\n",
    "            trial_price = trial_price * 0.95\n",
    "            row[\"price_calendar\"] = trial_price\n",
    "            df = pd.DataFrame(data=row.to_dict(), index=[0])\n",
    "            prob_booked_trial = clf.predict_proba(df)[0][0]\n",
    "#             print (\"trial_price: \" + str(trial_price))\n",
    "#             print (\"prob_booked_trial: \" + str(prob_booked_trial))\n",
    "\n",
    "            if prob_booked_trial >= prob_booked:\n",
    "                if prob_booked_trial == prob_booked:\n",
    "                    steps_in_trap += 1\n",
    "                    if steps_in_trap > 3:\n",
    "                        return saved_trial_price * prob_booked\n",
    "                else:\n",
    "                    steps_in_trap = 0\n",
    "                prob_booked = prob_booked_trial\n",
    "            else:\n",
    "                return saved_trial_price * prob_booked\n",
    "        return trial_price * prob_booked\n",
    "    else:\n",
    "#         print (\"Will try with increased the price\")\n",
    "        trial_price = current_price\n",
    "        saved_trial_price = None\n",
    "        steps_in_trap = 0\n",
    "        while (True):\n",
    "            saved_trial_price = trial_price\n",
    "            trial_price = trial_price * 1.05\n",
    "            row[\"price_calendar\"] = trial_price\n",
    "            df = pd.DataFrame(data=row.to_dict(), index=[0])\n",
    "            prob_booked_trial = clf.predict_proba(df)[0][0]\n",
    "#             print (\"trial_price: \" + str(trial_price))\n",
    "#             print (\"prob_booked_trial: \" + str(prob_booked_trial))\n",
    "            if prob_booked_trial <= prob_booked:\n",
    "                if prob_booked_trial == prob_booked:\n",
    "                    steps_in_trap += 1\n",
    "                    if steps_in_trap > 3:\n",
    "                        return saved_trial_price * prob_booked\n",
    "                else:\n",
    "                    steps_in_trap = 0\n",
    "                prob_booked = prob_booked_trial\n",
    "                if (prob_booked > threshold):\n",
    "                    pass\n",
    "                else:\n",
    "                    return saved_trial_price * prob_booked    \n",
    "            else:\n",
    "                return saved_trial_price * prob_booked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = pickle.load(open(\"gb_best.pkl\", 'rb'))\n",
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating revenue at threshold: 0.025\n",
      "Evaluating revenue at threshold: 0.05\n",
      "Evaluating revenue at threshold: 0.075\n",
      "Evaluating revenue at threshold: 0.1\n",
      "Evaluating revenue at threshold: 0.125\n",
      "Evaluating revenue at threshold: 0.15\n",
      "Evaluating revenue at threshold: 0.175\n",
      "Evaluating revenue at threshold: 0.2\n",
      "Evaluating revenue at threshold: 0.225\n",
      "Evaluating revenue at threshold: 0.25\n",
      "Evaluating revenue at threshold: 0.275\n",
      "Evaluating revenue at threshold: 0.3\n",
      "Evaluating revenue at threshold: 0.325\n",
      "Evaluating revenue at threshold: 0.35\n",
      "Evaluating revenue at threshold: 0.375\n",
      "Evaluating revenue at threshold: 0.4\n",
      "Evaluating revenue at threshold: 0.425\n",
      "Evaluating revenue at threshold: 0.45\n",
      "Evaluating revenue at threshold: 0.475\n",
      "Evaluating revenue at threshold: 0.5\n",
      "Evaluating revenue at threshold: 0.525\n",
      "Evaluating revenue at threshold: 0.55\n",
      "Evaluating revenue at threshold: 0.575\n",
      "Evaluating revenue at threshold: 0.6\n",
      "Evaluating revenue at threshold: 0.625\n",
      "Evaluating revenue at threshold: 0.65\n",
      "Evaluating revenue at threshold: 0.675\n",
      "Evaluating revenue at threshold: 0.7\n",
      "Evaluating revenue at threshold: 0.725\n",
      "Evaluating revenue at threshold: 0.75\n",
      "Evaluating revenue at threshold: 0.775\n",
      "Evaluating revenue at threshold: 0.8\n",
      "Evaluating revenue at threshold: 0.825\n",
      "Evaluating revenue at threshold: 0.85\n",
      "Evaluating revenue at threshold: 0.875\n",
      "Evaluating revenue at threshold: 0.9\n",
      "Evaluating revenue at threshold: 0.925\n",
      "Evaluating revenue at threshold: 0.95\n",
      "Evaluating revenue at threshold: 0.975\n"
     ]
    }
   ],
   "source": [
    "highest_revenue = -math.inf\n",
    "threshold_at_highest_revenue = None\n",
    "for threshold in thresholds:\n",
    "#     print(\"====================================================\\n\")    \n",
    "    print (\"Evaluating revenue at threshold: \" + str(threshold))\n",
    "#     print(\"====================================================\\n\")\n",
    "    revenue = 0\n",
    "    for index, row in X_test.sample(n=1000, random_state=42).copy().iterrows():\n",
    "        revenue_at_tuned_price = calc_revenue_at_tuned_price(row, threshold, clf)\n",
    "#         print (\"threshold: \" + str(threshold))\n",
    "#         print (\"revenue at tuned price: \" + str(revenue_at_tuned_price))\n",
    "        revenue += revenue_at_tuned_price\n",
    "#         print (\"------------------------------------------------------------\")\n",
    "    if revenue > highest_revenue:\n",
    "        highest_revenue = revenue\n",
    "        threshold_at_highest_revenue = threshold\n",
    "    revenue_by_threshold.loc[threshold, \"revenue\"] = revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.025</th>\n",
       "      <td>111800.952549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.050</th>\n",
       "      <td>111782.422364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.075</th>\n",
       "      <td>111760.902959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <td>111730.242050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.125</th>\n",
       "      <td>111723.260462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.150</th>\n",
       "      <td>111699.712817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.175</th>\n",
       "      <td>111521.937756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.200</th>\n",
       "      <td>111448.039145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.225</th>\n",
       "      <td>111451.742460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.250</th>\n",
       "      <td>111302.155145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.275</th>\n",
       "      <td>111051.244305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.300</th>\n",
       "      <td>110910.857264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.325</th>\n",
       "      <td>110856.074465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.350</th>\n",
       "      <td>110556.876992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.375</th>\n",
       "      <td>110512.982710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.400</th>\n",
       "      <td>110251.094696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.425</th>\n",
       "      <td>109932.721144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.450</th>\n",
       "      <td>109711.792726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.475</th>\n",
       "      <td>109329.627185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.500</th>\n",
       "      <td>108887.839472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.525</th>\n",
       "      <td>108194.861051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.550</th>\n",
       "      <td>107707.602314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.575</th>\n",
       "      <td>107431.981545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.600</th>\n",
       "      <td>106786.764851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.625</th>\n",
       "      <td>106191.125179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.650</th>\n",
       "      <td>105668.993195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.675</th>\n",
       "      <td>105150.726572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.700</th>\n",
       "      <td>104864.718100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.725</th>\n",
       "      <td>103532.171544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.750</th>\n",
       "      <td>103060.507547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.775</th>\n",
       "      <td>102536.282929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.800</th>\n",
       "      <td>101760.196995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.825</th>\n",
       "      <td>101071.161239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.850</th>\n",
       "      <td>99946.660402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.875</th>\n",
       "      <td>99110.295969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.900</th>\n",
       "      <td>98241.928010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.925</th>\n",
       "      <td>97076.743386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.950</th>\n",
       "      <td>95436.443935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.975</th>\n",
       "      <td>94746.337356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             revenue\n",
       "0.025  111800.952549\n",
       "0.050  111782.422364\n",
       "0.075  111760.902959\n",
       "0.100  111730.242050\n",
       "0.125  111723.260462\n",
       "0.150  111699.712817\n",
       "0.175  111521.937756\n",
       "0.200  111448.039145\n",
       "0.225  111451.742460\n",
       "0.250  111302.155145\n",
       "0.275  111051.244305\n",
       "0.300  110910.857264\n",
       "0.325  110856.074465\n",
       "0.350  110556.876992\n",
       "0.375  110512.982710\n",
       "0.400  110251.094696\n",
       "0.425  109932.721144\n",
       "0.450  109711.792726\n",
       "0.475  109329.627185\n",
       "0.500  108887.839472\n",
       "0.525  108194.861051\n",
       "0.550  107707.602314\n",
       "0.575  107431.981545\n",
       "0.600  106786.764851\n",
       "0.625  106191.125179\n",
       "0.650  105668.993195\n",
       "0.675  105150.726572\n",
       "0.700  104864.718100\n",
       "0.725  103532.171544\n",
       "0.750  103060.507547\n",
       "0.775  102536.282929\n",
       "0.800  101760.196995\n",
       "0.825  101071.161239\n",
       "0.850   99946.660402\n",
       "0.875   99110.295969\n",
       "0.900   98241.928010\n",
       "0.925   97076.743386\n",
       "0.950   95436.443935\n",
       "0.975   94746.337356"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revenue_by_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111800.95254882191"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_at_highest_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(revenue_by_threshold.index, revenue_by_threshold)\n",
    "plt.ylabel('Revenue projection')\n",
    "plt.xlabel('Threshold of probability for property to be booked')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating percentage of change in expected revenue before and after tuning price using occupancy prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_revenue_original_price = 0\n",
    "expected_revenue_modified_price = 0\n",
    "\n",
    "for index, row in X_test.sample(n=1000, random_state=42).copy().iterrows():\n",
    "    df = pd.DataFrame(data=row.to_dict(), index=[0])\n",
    "    prob_booked = clf.predict_proba(df)[0][0]\n",
    "    expected_revenue_original_price += prob_booked    * row[\"price_calendar\"]\n",
    "    \n",
    "    revenue_at_tuned_price = calc_revenue_at_tuned_price(row, threshold_at_highest_revenue, clf)\n",
    "    expected_revenue_modified_price += revenue_at_tuned_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentag_change = 100*(expected_revenue_modified_price - expected_revenue_original_price)/expected_revenue_original_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.729525101253397"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentag_change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from keras) (1.16.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from keras) (1.2.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from keras) (5.1)\n",
      "Requirement already satisfied: h5py in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: tensorflow in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (1.14.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from tensorflow) (0.33.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from tensorflow) (0.1.7)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from tensorflow) (1.11.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from tensorflow) (1.16.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from tensorflow) (1.22.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from tensorflow) (3.9.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from tensorflow) (0.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (41.0.1)\n",
      "Requirement already satisfied: h5py in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow) (2.9.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(n_features, learn_rate):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(150, input_shape=(n_features,),\n",
    "              kernel_initializer='glorot_normal'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(75, kernel_initializer='glorot_normal'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Dense(25, kernel_initializer='glorot_normal'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.10))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=Adam(lr=learn_rate),\n",
    "                  metrics=['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = make_model(len(X_train.drop(columns=[\"listing_id\"]).columns), 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "916150/916150 [==============================] - 200s 218us/step - loss: 0.6296 - acc: 0.6360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1aad728908>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.fit(X_train.drop(columns=[\"listing_id\"]), y_train.drop(columns=[\"listing_id\"]), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_nn = nn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392740/392740 [==============================] - 28s 71us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7273395635688923, 0.49317869328308805]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.evaluate(x=X_test,y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-203-c263fcb8e604>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds_nn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"macro\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"f1-score: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    718\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m    719\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    832\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    835\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1029\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test, y_preds_nn, average=\"macro\")\n",
    "print (\"f1-score: \" + str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[\"available\"].value_counts()/y_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see that the data available for classification is somewhat imbalanced. I am applying various approaches to ensure balance in the training received by the neural network based model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
